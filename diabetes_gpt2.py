# -*- coding: utf-8 -*-
"""diabetes_gpt2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YfIEHyxZSZjjIj3fz_mJdttZEL3QXFcX
"""

import pandas as pd
import torch
from transformers import GPT2LMHeadModel, GPT2Tokenizer, TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments

df = pd.read_csv('diabetes.csv')

# Menggabungkan input dan output menjadi satu kolom teks
df['text'] = df.apply(lambda row: f"{row['prompt']} Input: {row['input']} Output: {row['output']}", axis=1)

# Menyimpan ke file txt untuk digunakan dalam pelatihan
df['text'].to_csv('prepared_dataset.txt', index=False, header=False)

special_tokens = ["<|begin_of_text|>", "<|eot_id|>", "<|end_of_text|>", "<|start_header_id|>","<|end_header_id|>"]
#biar ga aneh aneh outputnya pake special token
tokenizer = GPT2Tokenizer.from_pretrained('gpt2')
model = GPT2LMHeadModel.from_pretrained('gpt2')

tokenizer.add_tokens(special_tokens)

# Fungsi untuk memuat dataset teks
def load_dataset(file_path, tokenizer, block_size=128):
    return TextDataset(
        tokenizer=tokenizer,
        file_path=file_path,
        block_size=block_size
    )

def create_data_collator(tokenizer):
    return DataCollatorForLanguageModeling(
        tokenizer=tokenizer,
        mlm=False,
    )

train_dataset = load_dataset('prepared_dataset.txt', tokenizer)
data_collator = create_data_collator(tokenizer)

# Memuat model dan resize embedding untuk token baru
model = GPT2LMHeadModel.from_pretrained('gpt2')
model.resize_token_embeddings(len(tokenizer))

training_args = TrainingArguments(
    output_dir='./results_diabet_gpt2',
    overwrite_output_dir=True,
    num_train_epochs=20,
    per_device_train_batch_size=4,
    save_steps=10_000,
    save_total_limit=2,
    prediction_loss_only=True,
)

trainer = Trainer(
    model=model,
    args=training_args,
    data_collator=data_collator,
    train_dataset=train_dataset,
)

trainer.train()

#model.save_pretrained('./diabetes_gpt2')
#tokenizer.save_pretrained('./diabetes_gpt2')

from transformers import GPT2LMHeadModel, GPT2Tokenizer

# Memuat model dan tokenizer
model = GPT2LMHeadModel.from_pretrained('./diabetes_gpt2')
tokenizer = GPT2Tokenizer.from_pretrained('./diabetes_gpt2')

# Menghasilkan teks
def hitGenAI(input_text):
    input_ids = tokenizer.encode(input_text, return_tensors='pt')

    # Mengatur parameter generate
    output = model.generate(
        input_ids,
        max_length=100,  # Batasi panjang output
        num_return_sequences=1,
        eos_token_id=tokenizer.convert_tokens_to_ids("<|end_of_text|>"),  # Menghentikan generasi pada token <EOS>
    )

    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)

    # Menampilkan hasil dengan membersihkan tambahan input
    if "Output:" in generated_text:
        generated_text = generated_text.split("Output:")[1].strip()

    filter_answer = generated_text.split('Input: ')[0]
    answer = generated_text.split('"\n"')[0]
    return answer

    

"""sangat sulit rupanya berurusan dengan generative ai yg spesifik bahas seputar diabetes, kadang bila kita kasih input yang beda konteks dia AI ini berusaha menjawab dengan konteks diabetes. dan juga ada beberapa pertanyaan yg membuat AI ini ngasih jawaban yg kurang bagus dan diluar konteks pertanyaan juga

well atleast udah bisa ngasih jawaban umum. sorry my team, ku tidak bisa berbuat lebih, soon next semester bakalan coba improve lagi sebagai bahan belajar atau mungkin jadi bahan tugas akhir hehe
"""

