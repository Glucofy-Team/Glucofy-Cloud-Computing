# -*- coding: utf-8 -*-
"""GI-Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zverkNzRG3KYAxGxo_wMXRgayC_RV2eY

### Import Library
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import tensorflow as tf

from sklearn import metrics
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.svm import SVR
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

"""### Load Data"""

data = pd.read_csv('https://raw.githubusercontent.com/Glucofy-Team/Glucofy-Machine-Learning/main/data/(modified)%20nutrition%20food%20dataset.csv')
data

"""**Correlation Matrix**"""

correlation_matrix = data[['glycemic_index', 'glycemic_load', 'calories (kcal)', 'proteins (g)', 'carbohydrates (g)', 'fats (g)']].corr()

plt.figure(figsize=(5, 5))
sns.heatmap(correlation_matrix, annot=True, fmt='.2f')
plt.title('Correlation Matrix')
plt.show()

"""### Preprocessing Data

- Separate numeric features and target variables.
"""

numeric_features = ['calories (kcal)', 'proteins (g)', 'carbohydrates (g)', 'fats (g)']
X = data[numeric_features]
y_gi = data['glycemic_index']

"""- Split the data into training and test sets."""

X_train, X_test, y_gi_train, y_gi_test = train_test_split(X, y_gi, test_size=0.1, random_state=42)

"""- Standardize the data to ensure the input features are balanced."""

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""### Glycemic Index Prediction"""

baseline_pred = np.mean(y_gi_train)
baseline_loss = np.mean(np.abs(y_gi_test - baseline_pred))
print(f'Baseline MAE Loss: {baseline_loss}')

"""#### Linear Regression"""

regression = LinearRegression()
regression_gi = regression.fit(X_train_scaled, y_gi_train)

def model_evaluation(model, X_test, y_test):
    y_pred = model.predict(X_test)

    MAE = metrics.mean_absolute_error(y_test, y_pred)
    MSE = metrics.mean_squared_error(y_test, y_pred)
    RMSE = np.sqrt(MSE)
    R2_Score = metrics.r2_score(y_test, y_pred)

    return MAE, MSE, RMSE, R2_Score

reg_mae, reg_mse, reg_rmse, reg_r2 = model_evaluation(regression_gi, X_test_scaled, y_gi_test)

regression_gi_df = pd.DataFrame([[reg_mae, reg_mse, reg_rmse, reg_r2]],
                                index=['Linear Reg.'],
                                columns=['MAE', 'MSE', 'RMSE' ,'R2-Score'])

regression_gi_df

"""#### Decision Tree"""

tree_regressor = DecisionTreeRegressor()
tree_regressor.fit(X_train_scaled, y_gi_train)

tree_mae, tree_mse, tree_rmse, tree_r2 = model_evaluation(tree_regressor, X_test_scaled, y_gi_test)

tree_gi_df = pd.DataFrame([[tree_mae, tree_mse, tree_rmse, tree_r2]],
                                index=['Decision Tree'],
                                columns=['MAE', 'MSE', 'RMSE' ,'R2-Score'])

tree_gi_df

"""#### Support Vector Regression"""

svr_regressor = SVR(kernel = 'rbf')
svr_regressor.fit(X_train_scaled, y_gi_train)

svr_mae, svr_mse, svr_rmse, svr_r2 = model_evaluation(tree_regressor, X_test_scaled, y_gi_test)

svr_gi_df = pd.DataFrame([[svr_mae, svr_mse, svr_rmse, svr_r2]],
                                index=['SVR'],
                                columns=['MAE', 'MSE', 'RMSE' ,'R2-Score'])

svr_gi_df

"""#### Neural Network"""

def create_nn_model_gi():

    model_gi = tf.keras.Sequential([
      tf.keras.layers.Input(shape=(len(numeric_features),)),
      tf.keras.layers.Dense(64, activation='relu'),
      tf.keras.layers.Dense(64, activation='relu'),
      tf.keras.layers.Dense(128, activation='relu'),
      tf.keras.layers.Dropout(0.2),
      tf.keras.layers.Dense(1, activation='relu')
    ])

    return model_gi

def adjust_learning_rate():

    model = create_nn_model_gi()

    lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-6 * 10**(epoch / 20))

    optimizer = tf.keras.optimizers.SGD(momentum=0.8)

    model.compile(loss=tf.keras.losses.Huber(),
                  optimizer=optimizer,
                  metrics=['mae'])

    history = model.fit(X_train_scaled, y_gi_train, epochs=100, callbacks=[lr_schedule], verbose=0)

    return history

lr_history_gi = adjust_learning_rate()

plt.semilogx(lr_history_gi.history['lr'], lr_history_gi.history['loss'])
plt.axis([1e-6, 1e-1, 0, 45])
plt.show()

nn_model_gi = create_nn_model_gi()
nn_model_gi.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=6e-3, momentum=0.8), loss=tf.keras.losses.Huber(), metrics=['mae'])

nn_model_gi.fit(X_train_scaled, y_gi_train, epochs=100, validation_data=(X_test_scaled, y_gi_test), verbose=2)

gi_loss, gi_mae = nn_model_gi.evaluate(X_test_scaled, y_gi_test, verbose=0)
print("Glycemic Index Model MAE:", gi_mae)

y_gi_prediction = nn_model_gi.predict(X_test_scaled)

print('Predicted GI values: ', [f'{val[0]:.2f}' for val in y_gi_prediction[:30]])
print('True GI values:      ', [f'{val:.2f}' for val in y_gi_test[:30]])

"""### Save Model"""

mae_dict = {
    'Linear Regression': reg_mae,
    'Decision Tree': tree_mae,
    'SVR': svr_mae,
    'Neural Network': gi_mae
}

best_model = min(mae_dict, key=mae_dict.get)

print("Model with lowest MAE:", best_model)
print("MAE: ", mae_dict[best_model])

if best_model == 'Linear Regression':
    best_model = regression_gi
elif best_model == 'Decision Tree':
    best_model = tree_regressor
elif best_model == 'SVR':
    best_model = svr_regressor
elif best_model == 'Neural Network':
    best_model = nn_model_gi

best_model.save('Glycemic Index Model.h5')