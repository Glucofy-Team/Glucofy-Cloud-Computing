# -*- coding: utf-8 -*-
"""Copy of GIycemic Index Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xnJkD1n_Yrpfr1A5G3FfT3uQW9DM725r

### Import Library
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.losses import Huber
from keras.callbacks import EarlyStopping
from sklearn import metrics
from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder
from sklearn.model_selection import train_test_split

"""### Load Data"""

data = pd.read_csv('https://raw.githubusercontent.com/Glucofy-Team/Glucofy-Machine-Learning/main/data/nutrition%20food%20dataset%20-%20modified.csv')
data

"""**Correlation Matrix**"""

correlation_matrix = data[['glycemic_index', 'glycemic_load', 'calories (kcal)', 'proteins (g)', 'carbohydrates (g)', 'fats (g)']].corr()
"""
plt.figure(figsize=(5, 5))
sns.heatmap(correlation_matrix, annot=True, fmt='.2f')
plt.title('Correlation Matrix')
plt.show()
"""
"""### Preprocessing Data"""

def categorize_gi_new(gi):
    if gi <= 55:
        return 'Low'
    elif gi <= 69:
        return 'Medium'
    else:
        return 'High'

data['gi_category'] = data['glycemic_index'].apply(categorize_gi_new)

"""- Separate numeric features and target variables."""

numeric_features = ['calories (kcal)', 'proteins (g)', 'carbohydrates (g)', 'fats (g)']
X = data[numeric_features]

y_gi = data['glycemic_index']
y_gi_category = data['gi_category']

"""- Using one hot encoding for category classification."""

label_encoder_gi = LabelEncoder()
y_gi_category_encoded = label_encoder_gi.fit_transform(y_gi_category)

onehot_encoder = OneHotEncoder(sparse_output=False)
y_gi_category_onehot = onehot_encoder.fit_transform(y_gi_category_encoded.reshape(-1, 1))

y_gi_array = y_gi.to_numpy()

y_combined = np.column_stack((y_gi_category_onehot, y_gi_array))

"""- Split the data into training and test sets."""

X_train, X_test, y_train, y_test = train_test_split(X, y_combined, test_size=0.1, random_state=42)

"""- Standardize the data to ensure the input features are balanced."""

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""### Build and Train Model"""

input_shape = X_train.shape[1]

inputs = tf.keras.Input(shape=(input_shape,))

x = tf.keras.layers.Dense(32, activation='relu')(inputs)
x = tf.keras.layers.Dense(32, activation='relu')(x)
x = tf.keras.layers.Dense(128, activation='relu')(x)
x = tf.keras.layers.Dense(128, activation='relu')(x)
x = tf.keras.layers.Dropout(0.2)(x)
x = tf.keras.layers.Dense(64, activation='relu')(x)

num_categories = y_gi_category_onehot.shape[1]
output1 = tf.keras.layers.Dense(num_categories, activation='softmax', name='category_output')(x)
output2 = tf.keras.layers.Dense(1, activation='relu', name='gi_output')(x)

model = tf.keras.Model(inputs=inputs, outputs=[output1, output2])

y_train_category = y_train[:, :num_categories]
y_train_gi = y_train[:, num_categories]

y_test_category = y_test[:, :num_categories]
y_test_gi = y_test[:, num_categories]

def adjust_learning_rate():

    lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-6 * 10**(epoch / 20))

    optimizer = tf.keras.optimizers.Adam()

    model.compile(optimizer=optimizer,
              loss={'category_output': 'categorical_crossentropy', 'gi_output': tf.keras.losses.Huber()},
              metrics={'category_output': 'accuracy', 'gi_output': 'mae'})

    history = model.fit(X_train_scaled,
                        {'category_output': y_train_category, 'gi_output': y_train_gi},
                        epochs=100,
                        callbacks=[lr_schedule],
                        verbose=0)

    return history

lr_history = adjust_learning_rate()
"""
plt.semilogx(lr_history.history['lr'], lr_history.history['loss'])
plt.axis([1e-6, 1e-1, 0, 45])
plt.show()
"""
model = tf.keras.Model(inputs=inputs, outputs=[output1, output2])

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-3),
              loss={'category_output': 'categorical_crossentropy', 'gi_output': tf.keras.losses.Huber()},
              metrics={'category_output': 'accuracy', 'gi_output': 'mae'})

model.fit(
    X_train_scaled,
    {'category_output': y_train_category, 'gi_output': y_train_gi},
    epochs=75,
    validation_data=(X_test_scaled, {'category_output': y_test_category, 'gi_output': y_test_gi}),
    verbose=2)

"""### Evaluate Model"""

results = model.evaluate(X_test_scaled, {'category_output': y_test_category, 'gi_output': y_test_gi})

#print(f"GI Category Accuracy: {results[3]:.4f}")
#print(f"GI MAE: {results[4]:.4f}")

new_data = np.array([[105.0, 8.1, 18.5, 1.9]])
new_data_scaled = scaler.transform(new_data)

new_prediction = model.predict(new_data_scaled)
gi_new_prediction = round((new_prediction[1])[0][0])
gi_new_category = new_prediction[0]

category_index = np.argmax(gi_new_category, axis=1)
category_label = label_encoder_gi.inverse_transform(category_index)

print('Glycemic Index Prediction: ', gi_new_prediction)
print('Glycemic Index Category:', category_label[0])

"""### Save Model"""

model.save('Glycemic Index Model.h5')

def predict_gi(calories, proteins, carbohydrates, fats):
    new_data = np.array([[calories, proteins, carbohydrates, fats]])
    new_data_scaled = scaler.transform(new_data)

    new_prediction = model.predict(new_data_scaled)
    gi_new_prediction = round((new_prediction[1])[0][0])
    gi_new_category = new_prediction[0]

    category_index = np.argmax(gi_new_category, axis=1)
    category_label = label_encoder_gi.inverse_transform(category_index)

    print('Glycemic Index Prediction: ', gi_new_prediction)
    print('Glycemic Index Category:', category_label[0])

    return gi_new_prediction, category_label[0]



